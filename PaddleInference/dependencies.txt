F:\yaml-cpp\include
F:\gflags-master\out\include
D:\paddle_inference_tools\paddle_inference\paddle\include
D:\paddle_inference_tools\paddle_inference\third_party\install\cryptopp\include
D:\paddle_inference_tools\paddle_inference\third_party\install\mkldnn\include
D:\paddle_inference_tools\paddle_inference\third_party\install\xxhash\include
D:\paddle_inference_tools\paddle_inference\third_party\install\utf8proc\include
D:\paddle_inference_tools\paddle_inference\third_party\install\protobuf\include
D:\paddle_inference_tools\paddle_inference\third_party\install\paddle2onnx\include
D:\paddle_inference_tools\paddle_inference\third_party\install\onnxruntime\include
D:\paddle_inference_tools\paddle_inference\third_party\install\mklml\include
D:\opencv\build\include





F:\yaml-cpp\build\Release
F:\gflags-master\out\lib\Release
D:\paddle_inference_tools\paddle_inference\third_party\install\xxhash\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\utf8proc\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\protobuf\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\paddle2onnx\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\onnxruntime\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\mklml\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\mkldnn\lib
D:\paddle_inference_tools\paddle_inference\third_party\install\cryptopp\lib
D:\paddle_inference_tools\paddle_inference\paddle\lib
D:\opencv\build\x64\vc15\lib

opencv_world455.lib
mklml.lib
libiomp5md.lib
paddle_inference.lib
libpaddle_inference.lib
onnxruntime.lib
paddle2onnx.lib
libprotobuf.lib
utf8proc_static.lib
xxhash.lib
mkldnn.lib
gflags_static.lib
gflags_nothreads_static.lib
libyaml-cppmd.lib
shlwapi.lib
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7\lib\x64\cudart.lib
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7\lib\x64\cublas.lib
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7\lib\x64\cudnn.lib
cryptopp-static.lib


